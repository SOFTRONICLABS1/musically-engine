<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Musically Engine - Using Real Engine Bundle</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            min-height: 100vh;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #4a5568;
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
        }
        
        .subtitle {
            text-align: center;
            color: #718096;
            margin-bottom: 30px;
            font-size: 1.2em;
        }
        
        .status-banner {
            background: linear-gradient(135deg, #48bb78, #38a169);
            color: white;
            padding: 15px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 30px;
            font-weight: bold;
            font-size: 1.1em;
        }
        
        .test-section {
            background: white;
            padding: 25px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .test-section h3 {
            color: #2d3748;
            margin-bottom: 15px;
            font-size: 1.4em;
            border-bottom: 2px solid #e2e8f0;
            padding-bottom: 10px;
        }
        
        .controls {
            display: flex;
            gap: 15px;
            margin-bottom: 15px;
            flex-wrap: wrap;
            align-items: center;
        }
        
        .controls label {
            font-weight: bold;
            color: #4a5568;
        }
        
        .controls select,
        .controls input {
            padding: 8px;
            border: 1px solid #cbd5e0;
            border-radius: 5px;
            background: white;
            font-size: 14px;
        }
        
        button {
            padding: 10px 20px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-weight: bold;
            font-size: 14px;
            transition: transform 0.2s;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .verify-btn {
            background: linear-gradient(135deg, #48bb78, #38a169);
            animation: pulse 2s infinite;
        }

        .verify-btn:disabled {
            animation: none;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .validation-section {
            background: #f0fff4;
            padding: 20px;
            margin: 20px 0;
            border-radius: 12px;
            border: 2px solid #48bb78;
        }

        .validation-controls {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin-bottom: 20px;
        }

        .playback-buttons, .analysis-buttons {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }

        .playback-buttons button {
            background: linear-gradient(135deg, #4299e1, #3182ce);
        }

        .analysis-buttons button {
            background: linear-gradient(135deg, #ed8936, #dd6b20);
        }

        .confidence-results {
            background: white;
            padding: 20px;
            border-radius: 8px;
            border: 1px solid #e2e8f0;
        }

        .overall-score {
            text-align: center;
            margin-bottom: 20px;
        }

        .score-bar {
            background: #e2e8f0;
            height: 20px;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }

        .score-fill {
            height: 100%;
            background: linear-gradient(90deg, #fc8181, #f6ad55, #68d391, #4fd1c7);
            transition: width 0.5s ease;
        }

        .detailed-breakdown {
            display: grid;
            grid-template-columns: 1fr;
            gap: 10px;
            margin: 20px 0;
        }

        .metric {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px;
            background: #f7fafc;
            border-radius: 6px;
        }

        .metric .score {
            font-weight: bold;
            color: #2d3748;
        }

        .metric .details {
            font-size: 12px;
            color: #718096;
        }

        .recommendations {
            background: #ebf8ff;
            padding: 15px;
            border-radius: 6px;
            border-left: 4px solid #4299e1;
        }

        .recommendations ul {
            margin: 10px 0;
            padding-left: 20px;
        }

        .recommendations li {
            margin: 5px 0;
        }
        
        #liveAnalysis {
            background: #f7fafc;
            padding: 20px;
            border-radius: 8px;
            min-height: 200px;
            font-family: 'Courier New', monospace;
            white-space: pre-wrap;
            border: 2px solid #e2e8f0;
        }
        
        .analysis-line {
            margin: 5px 0;
            padding: 5px;
            background: white;
            border-radius: 4px;
        }
        
        .error {
            color: #e53e3e;
            background-color: #fff5f5;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        
        .success {
            color: #38a169;
            background-color: #f0fff4;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        
        .info {
            color: #3182ce;
            background-color: #ebf8ff;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        
        .loading {
            text-align: center;
            padding: 20px;
            color: #718096;
        }
        
        .pitch-display {
            font-size: 24px;
            font-weight: bold;
            color: #667eea;
            margin: 10px 0;
        }
        
        .confidence-bar {
            width: 100%;
            height: 20px;
            background: #e2e8f0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }
        
        .confidence-fill {
            height: 100%;
            background: linear-gradient(90deg, #48bb78, #38a169);
            transition: width 0.3s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎵 Musically Engine Test Interface</h1>
        <div class="subtitle">Using Real TypeScript Engine Bundle</div>
        
        <div class="status-banner">
            ✅ Engine Status: <span id="engineStatus">Loading...</span>
        </div>
        
        <!-- Engine Information -->
        <div class="test-section">
            <h3>📊 Engine Information</h3>
            <div id="engineInfo">
                <div class="loading">Loading engine bundle...</div>
            </div>
        </div>
        
        <!-- Live Microphone Music Analysis -->
        <div class="test-section">
            <h3>🎤 Live Microphone Music Analysis</h3>
            <p>Real-time audio analysis using your actual TypeScript engine:</p>
            
            <div class="controls">
                <label>Audio Type:</label>
                <select id="audioType">
                    <option value="vocal">🎤 Vocal</option>
                    <option value="instrument">🎸 Instrument</option>
                </select>
                
                <label>Music System:</label>
                <select id="musicSystem">
                    <option value="western">🎼 Western</option>
                    <option value="carnatic" selected>🎵 Carnatic</option>
                    <option value="hindustani">🎶 Hindustani</option>
                </select>
                
            </div>
            
            <div class="controls">
                <label>Shruti (Sa):</label>
                <select id="shrutiSelect">
                    <option value="auto">🎯 Auto-Detect</option>
                    <option value="246.94">B (246.94 Hz)</option>
                    <option value="261.63">C (261.63 Hz)</option>
                    <option value="277.18">C# (277.18 Hz)</option>
                    <option value="293.66">D (293.66 Hz)</option>
                    <option value="311.13">D# (311.13 Hz)</option>
                    <option value="329.63">E (329.63 Hz)</option>
                    <option value="349.23">F (349.23 Hz)</option>
                    <option value="369.99">F# (369.99 Hz)</option>
                    <option value="392.00">G (392.00 Hz)</option>
                    <option value="415.30">G# (415.30 Hz)</option>
                    <option value="440.00">A (440.00 Hz)</option>
                    <option value="466.16">A# (466.16 Hz)</option>
                </select>
                
                <button onclick="startShrutiDetection()" id="detectShrutiBtn">🎵 Detect Shruti (Sa-Pa-Sa)</button>
                <button onclick="playSaPaDemo()" id="demoBtn">🔊 Play Sa-Pa-Sa Demo</button>
            </div>
            
            <div class="controls">
                <button onclick="startMicrophoneAnalysis()" id="startMicBtn">🎤 Start Microphone</button>
                <button onclick="stopMicrophoneAnalysis()" id="stopMicBtn" disabled>⏹️ Stop</button>
                <button onclick="verifyWhatYouSang()" id="verifyBtn" class="verify-btn" disabled style="display: none;">🔍 Verify What You Sang</button>
                <button onclick="testEngine()" id="testEngineBtn" style="background: orange;">🔧 Test Engine</button>
                <button onclick="clearAnalysis()">🗑️ Clear</button>
            </div>
            
            <div id="liveAnalysis" style="
                height: 300px; 
                overflow-y: auto; 
                border: 2px solid #ddd; 
                border-radius: 8px; 
                padding: 15px; 
                background: #fafafa;
                font-family: 'Courier New', monospace;
                font-size: 14px;
                line-height: 1.4;
                white-space: pre-wrap;
            "></div>
        </div>
        
        <!-- Validation Interface -->
        <div class="validation-section" id="validationSection" style="display: none;">
            <h3>🔬 Engine Validation & Analysis</h3>
            
            <div class="validation-controls">
                <div class="playback-buttons">
                    <button onclick="playOriginalRecording()" id="playOriginalBtn" disabled>
                        🎤 Play Your Voice
                    </button>
                    <button onclick="playEngineDetection()" id="playEngineBtn" disabled>
                        🔍 Play Engine Output
                    </button>
                    <button onclick="playBothTogether()" id="playBothBtn" disabled>
                        ⚖️ Compare Both
                    </button>
                </div>
                
                <div class="analysis-buttons">
                    <button onclick="runConfidenceAnalysis()" id="analyzeBtn" disabled>
                        🎖️ Analyze Confidence
                    </button>
                    <button onclick="downloadRecording()" id="downloadBtn" disabled>
                        💾 Download Recording
                    </button>
                </div>
            </div>
            
            <div class="confidence-results" id="confidenceResults" style="display: none;">
                <!-- Confidence analysis results will be inserted here -->
            </div>
        </div>
        
        <!-- Test Audio Generation -->
        <div class="test-section">
            <h3>🎹 Test Audio Generation</h3>
            <div class="controls">
                <label>Test Note:</label>
                <select id="testNote">
                    <option value="261.63">C4 (261.63 Hz)</option>
                    <option value="293.66">D4 (293.66 Hz)</option>
                    <option value="329.63">E4 (329.63 Hz)</option>
                    <option value="349.23">F4 (349.23 Hz)</option>
                    <option value="392.00">G4 (392.00 Hz)</option>
                    <option value="440.00">A4 (440.00 Hz)</option>
                    <option value="493.88">B4 (493.88 Hz)</option>
                </select>
                
                <button onclick="playTestNote()">▶️ Play</button>
                <button onclick="stopTestNote()">⏹️ Stop</button>
                <button onclick="analyzeTestNote()">📊 Analyze</button>
            </div>
            <div id="testNoteAnalysis"></div>
        </div>
    </div>
    
    <!-- Load the compiled engine bundle -->
    <script src="dist/browser/musically-engine.umd.js"></script>
    
    <!-- Application code that uses the engine -->
    <script>
        // Global variables
        let audioContext;
        let microphoneStream;
        let analyzerNode;
        let microphoneSource;
        let animationFrame;
        let isAnalyzing = false;
        
        // Store detected notes for verification playback
        let detectedNotes = [];
        let sessionStartTime = null;
        
        // Audio recording system for validation
        let mediaRecorder = null;
        let recordedChunks = [];
        let recordedAudioBlob = null;
        let recordedAudioUrl = null;
        
        // Adaptive noise floor learning
        let noiseFloor = 0;
        let noiseFloorSamples = 0;
        let noiseCalibrationComplete = false;
        let engine = null;
        let musicSystem = null;
        let audioProcessor = null;
        let testOscillator = null;
        
        // Sa-Pa-Sa shruti detection variables
        let isDetectingShruti = false;
        let saPaPatternBuffer = [];
        let detectedSaFrequency = null;
        let detectedPaFrequency = null;
        let saPaCycles = 0;
        
        // Initialize engine when page loads
        window.addEventListener('DOMContentLoaded', async () => {
            try {
                // Check if MusicallyEngine is available
                if (typeof MusicallyEngine === 'undefined') {
                    throw new Error('MusicallyEngine bundle not loaded');
                }
                
                // Initialize the engine
                engine = new MusicallyEngine.MusicallyEngine();
                await engine.initialize();
                
                // Create music system
                const systemType = document.getElementById('musicSystem').value;
                musicSystem = MusicallyEngine.createMusicSystem(systemType, 440); // Use standard 440Hz
                
                // Create audio processor
                const processorConfig = {
                    sampleRate: 44100,
                    frameSize: 2048,
                    audioType: document.getElementById('audioType').value
                };
                audioProcessor = new MusicallyEngine.AdaptiveProcessor(processorConfig);
                
                // Update UI
                document.getElementById('engineStatus').textContent = 'Ready';
                document.getElementById('engineInfo').innerHTML = `
                    <div class="success">
                        ✅ Engine loaded successfully!<br>
                        Version: ${MusicallyEngine.version || '1.0.0'}<br>
                        Music Systems: Western, Carnatic, Hindustani<br>
                        Audio Processors: Vocal, Instrument, Adaptive<br>
                        Algorithms: YIN, Autocorrelation, HPS, FFT
                    </div>
                `;
            } catch (error) {
                console.error('Engine initialization error:', error);
                document.getElementById('engineStatus').textContent = 'Error';
                document.getElementById('engineInfo').innerHTML = `
                    <div class="error">
                        ❌ Failed to load engine: ${error.message}<br>
                        Please check that the bundle was built correctly.
                    </div>
                `;
            }
        });
        
        // Update music system when selection changes
        document.getElementById('musicSystem').addEventListener('change', (e) => {
            if (engine && MusicallyEngine) {
                musicSystem = MusicallyEngine.createMusicSystem(e.target.value, 440); // Use standard 440Hz
            }
        });
        
        
        document.getElementById('audioType').addEventListener('change', (e) => {
            if (audioProcessor) {
                audioProcessor.updateConfig({ audioType: e.target.value });
            }
        });
        
        // Initialize audio context
        function initAudio() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
        }
        
        // Start microphone analysis
        async function startMicrophoneAnalysis() {
            try {
                // Initialize session
                detectedNotes = [];
                sessionStartTime = Date.now();
                recordedChunks = [];
                recordedAudioBlob = null;
                
                // Clean up previous recording URL
                if (recordedAudioUrl) {
                    URL.revokeObjectURL(recordedAudioUrl);
                    recordedAudioUrl = null;
                }
                
                initAudio();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                // Get microphone access
                microphoneStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    } 
                });
                
                // Create audio nodes
                microphoneSource = audioContext.createMediaStreamSource(microphoneStream);
                analyzerNode = audioContext.createAnalyser();
                analyzerNode.fftSize = 2048;
                
                microphoneSource.connect(analyzerNode);
                
                // Setup audio recording for validation
                setupAudioRecording(microphoneStream);
                
                isAnalyzing = true;
                document.getElementById('startMicBtn').disabled = true;
                document.getElementById('stopMicBtn').disabled = false;
                
                analyzeMicrophone();
            } catch (error) {
                console.error('Microphone error:', error);
                document.getElementById('liveAnalysis').innerHTML = `
                    <div class="error">❌ Microphone error: ${error.message}</div>
                `;
            }
        }
        
        // Analyze microphone input
        async function analyzeMicrophone() {
            if (!isAnalyzing) return;
            
            const bufferLength = analyzerNode.fftSize;
            const dataArray = new Float32Array(bufferLength);
            analyzerNode.getFloatTimeDomainData(dataArray);
            
            // Calculate RMS amplitude for noise gating
            let rms = 0;
            let peak = 0;
            for (let i = 0; i < dataArray.length; i++) {
                const sample = Math.abs(dataArray[i]);
                rms += dataArray[i] * dataArray[i];
                if (sample > peak) peak = sample;
            }
            rms = Math.sqrt(rms / dataArray.length);
            
            // Learn noise floor during first few seconds
            if (!noiseCalibrationComplete && noiseFloorSamples < 150) { // ~5 seconds at 30fps
                noiseFloor = (noiseFloor * noiseFloorSamples + rms) / (noiseFloorSamples + 1);
                noiseFloorSamples++;
                
                if (noiseFloorSamples >= 150) {
                    noiseCalibrationComplete = true;
                    console.log(`Noise floor calibrated: ${noiseFloor.toFixed(4)}`);
                    updateAnalysisDisplay(`<div class="info">🔇 Noise floor calibrated: ${noiseFloor.toFixed(4)}. Ready for analysis!</div>`);
                }
                
                animationFrame = requestAnimationFrame(analyzeMicrophone);
                return;
            }
            
            // Enhanced noise gate with adaptive thresholds based on learned noise floor
            const adaptiveRmsThreshold = Math.max(0.05, noiseFloor * 5); // At least 5x noise floor
            const peakThreshold = Math.max(0.1, noiseFloor * 8);         // At least 8x noise floor
            const dynamicRange = peak / (rms + 0.001); // Avoid division by zero
            
            // 🔧 DEBUGGING: More detailed noise gate logging
            if (noiseCalibrationComplete) {
                console.log(`🔧 Noise Gate Check:`, {
                    rms: rms.toFixed(4),
                    peak: peak.toFixed(4),
                    noiseFloor: noiseFloor.toFixed(4),
                    adaptiveRmsThreshold: adaptiveRmsThreshold.toFixed(4),
                    peakThreshold: peakThreshold.toFixed(4),
                    dynamicRange: dynamicRange.toFixed(2),
                    passesGate: rms >= adaptiveRmsThreshold && peak >= peakThreshold && dynamicRange >= 3.0
                });
            }
            
            // 🔧 TEMPORARY: Bypass noise gate for debugging
            const bypassNoiseGate = true; // Set to false to re-enable noise gate
            
            // Only process if signal is significantly above noise floor AND has good dynamic range
            if (!bypassNoiseGate && (rms < adaptiveRmsThreshold || peak < peakThreshold || dynamicRange < 3.0)) {
                // Signal too quiet or lacks dynamic range - likely noise
                if (noiseCalibrationComplete) {
                    console.log('🚫 Signal rejected by noise gate');
                }
                animationFrame = requestAnimationFrame(analyzeMicrophone);
                return;
            }
            
            if (bypassNoiseGate && noiseCalibrationComplete) {
                console.log('🔧 BYPASSING noise gate for debugging');
            }
            
            console.log(`Audio levels - RMS: ${rms.toFixed(4)}, Peak: ${peak.toFixed(4)}, Ratio: ${dynamicRange.toFixed(2)}`); // Debug log
            
            // Process with the engine
            if (audioProcessor && musicSystem) {
                try {
                    console.log('🔧 Processing audio with engine...', {
                        bufferLength: dataArray.length,
                        bufferSample: dataArray.slice(0, 10),
                        hasAudioProcessor: !!audioProcessor,
                        hasMusicSystem: !!musicSystem
                    });
                    
                    const result = await audioProcessor.processAudio(dataArray);
                    console.log('🔧 Engine Analysis result:', result); // Debug log
                    
                    if (result && result.fundamentalFrequency > 50) {
                        const musicAnalysis = musicSystem.analyzeFrequency(result.fundamentalFrequency);
                        
                        // Store detected note for verification playback
                        const noteData = {
                            frequency: result.fundamentalFrequency,
                            timestamp: Date.now(),
                            relativeTime: Date.now() - sessionStartTime,
                            analysis: getDetailedSvaraAnalysis(result.fundamentalFrequency)
                        };
                        detectedNotes.push(noteData);
                        
                        // Enhanced display with Shruti detection for Indian systems
                        const displayText = await formatAnalysisResultWithShruti(result, musicAnalysis);
                        updateAnalysisDisplay(displayText);
                    } else {
                        // Debug output for failed analysis
                        if (!result) {
                            console.log('No result from processAudio');
                        } else if (!result.fundamentalFrequency) {
                            console.log('No fundamentalFrequency in result:', result);
                        } else if (result.fundamentalFrequency <= 50) {
                            console.log('Frequency too low:', result.fundamentalFrequency);
                        }
                    }
                } catch (error) {
                    console.error('Analysis error:', error);
                    updateAnalysisDisplay(`<div class="error">Analysis Error: ${error.message}</div>`);
                }
            } else {
                // Debug: Check if components are missing
                if (!audioProcessor) {
                    console.log('❌ No audioProcessor');
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ AudioProcessor not initialized`);
                }
                if (!musicSystem) {
                    console.log('❌ No musicSystem');
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ MusicSystem not initialized`);
                }
            }
            
            animationFrame = requestAnimationFrame(analyzeMicrophone);
        }
        
        // Enhanced format analysis result with Shruti detection
        async function formatAnalysisResultWithShruti(audioResult, musicResult) {
            const timestamp = new Date().toLocaleTimeString();
            let output = `[${timestamp}] `;
            
            const systemType = document.getElementById('musicSystem').value;
            const frequency = audioResult.fundamentalFrequency;
            
            // Indian music systems with detailed Shruti analysis
            if (systemType === 'carnatic' || systemType === 'hindustani') {
                const analysis = getDetailedSvaraAnalysis(frequency);
                
                // Format: Closest Swara, Closest Octave, actual Frequency (Shruthi set by user)
                output += `Closest Swara: ${analysis.closestSvara} | `;
                output += `Closest Octave: ${analysis.closestOctave} | `;
                output += `Actual Frequency: ${analysis.actualFrequency.toFixed(2)} Hz`;
                
                // Add cents deviation if significant
                if (Math.abs(analysis.cents) > 5) {
                    output += ` (${analysis.cents > 0 ? '+' : ''}${analysis.cents} cents)`;
                }
                
                return output;
            }
            
            // Fallback to original formatting for Western
            return formatAnalysisResult(audioResult, musicResult);
        }
        
        // Convert frequency to closest Indian Svara with detailed analysis
        function getDetailedSvaraAnalysis(frequency) {
            // Get user-selected Shruti (Sa frequency)
            const shrutiSelect = document.getElementById('shrutiSelect');
            let saFreq = 261.63; // Default to C4
            
            if (shrutiSelect.value !== 'auto') {
                saFreq = parseFloat(shrutiSelect.value);
            }
            
            // Find the closest octave first
            let octave = Math.round(Math.log2(frequency / saFreq));
            let baseFreqForOctave = saFreq * Math.pow(2, octave);
            
            // Calculate ratio within the octave
            let ratio = frequency / baseFreqForOctave;
            
            // If ratio is too high or low, adjust octave
            while (ratio >= 2.0) {
                octave++;
                baseFreqForOctave *= 2;
                ratio = frequency / baseFreqForOctave;
            }
            while (ratio < 0.5) {
                octave--;
                baseFreqForOctave /= 2;
                ratio = frequency / baseFreqForOctave;
            }
            
            // Define Svara frequency ratios (just intonation)
            const svaras = [
                { name: 'Sa', ratio: 1.000, western: 'C' },
                { name: 'Ri', ratio: 1.125, western: 'D' },    // 9/8
                { name: 'Ga', ratio: 1.250, western: 'E' },    // 5/4
                { name: 'Ma', ratio: 1.333, western: 'F' },    // 4/3
                { name: 'Pa', ratio: 1.500, western: 'G' },    // 3/2
                { name: 'Dha', ratio: 1.667, western: 'A' },   // 5/3
                { name: 'Ni', ratio: 1.875, western: 'B' }     // 15/8
            ];
            
            // Find closest Svara
            let closestSvara = svaras[0];
            let minDifference = Math.abs(ratio - svaras[0].ratio);
            
            for (let svara of svaras) {
                let difference = Math.abs(ratio - svara.ratio);
                if (difference < minDifference) {
                    minDifference = difference;
                    closestSvara = svara;
                }
            }
            
            // Calculate octave name
            let octaveName;
            if (octave < 0) octaveName = 'Mandra';
            else if (octave === 0) octaveName = 'Madhya';
            else if (octave === 1) octaveName = 'Tara';
            else if (octave > 1) octaveName = `Tara+${octave-1}`;
            else octaveName = `Mandra+${Math.abs(octave)-1}`;
            
            // Calculate closest frequency and cents deviation
            const closestFreq = baseFreqForOctave * closestSvara.ratio;
            const cents = Math.round(1200 * Math.log2(frequency / closestFreq));
            
            // Western note equivalent (with octave number)
            const westernOctaveNumber = 4 + octave;
            const westernNote = `${closestSvara.western}${westernOctaveNumber}`;
            
            return {
                closestSvara: closestSvara.name,
                closestOctave: octaveName,
                actualFrequency: frequency,
                cents: cents,
                closestFreq: closestFreq
            };
        }
        
        // Original format analysis result (for Western)
        function formatAnalysisResult(audioResult, musicResult) {
            const timestamp = new Date().toLocaleTimeString();
            let output = `[${timestamp}] `;
            
            const systemType = document.getElementById('musicSystem').value;
            
            switch (systemType) {
                case 'western':
                    output += `Note: ${musicResult.note} | `;
                    output += `Frequency: ${audioResult.fundamentalFrequency.toFixed(2)} Hz | `;
                    output += `Cents: ${musicResult.cents > 0 ? '+' : ''}${musicResult.cents} | `;
                    output += `Confidence: ${(audioResult.confidence * 100).toFixed(1)}%`;
                    break;
                    
                case 'carnatic':
                    output += `Swara: ${musicResult.swara} | `;
                    output += `Octave: ${musicResult.octave} | `;
                    output += `Frequency: ${audioResult.fundamentalFrequency.toFixed(2)} Hz | `;
                    output += `Cents: ${musicResult.cents > 0 ? '+' : ''}${musicResult.cents}`;
                    if (musicResult.possibleRagas && musicResult.possibleRagas.length > 0) {
                        output += ` | Ragas: ${musicResult.possibleRagas.slice(0, 3).join(', ')}`;
                    }
                    break;
                    
                case 'hindustani':
                    output += `Swara: ${musicResult.swara} | `;
                    output += `Octave: ${musicResult.octave} | `;
                    output += `Frequency: ${audioResult.fundamentalFrequency.toFixed(2)} Hz | `;
                    output += `Cents: ${musicResult.cents > 0 ? '+' : ''}${musicResult.cents}`;
                    if (musicResult.possibleRagas && musicResult.possibleRagas.length > 0) {
                        output += ` | Ragas: ${musicResult.possibleRagas.slice(0, 3).join(', ')}`;
                    }
                    break;
            }
            
            return output;
        }
        
        // Update analysis display (scrollable, preserves all logs)
        function updateAnalysisDisplay(text) {
            const display = document.getElementById('liveAnalysis');
            
            // Append new line instead of replacing
            display.innerHTML += text + '\n';
            
            // Auto-scroll to bottom to show latest
            display.scrollTop = display.scrollHeight;
        }
        
        // Setup audio recording for validation
        function setupAudioRecording(stream) {
            try {
                // Create MediaRecorder with high quality settings
                const options = {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 128000
                };
                
                // Fallback for browsers that don't support webm
                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                    options.mimeType = 'audio/mp4';
                }
                
                mediaRecorder = new MediaRecorder(stream, options);
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    // Create audio blob from recorded chunks
                    recordedAudioBlob = new Blob(recordedChunks, { 
                        type: mediaRecorder.mimeType || 'audio/webm' 
                    });
                    recordedAudioUrl = URL.createObjectURL(recordedAudioBlob);
                    
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🎙️ Audio recording saved (${(recordedAudioBlob.size / 1024).toFixed(1)} KB)`);
                    
                    // Show validation UI
                    showValidationInterface();
                };
                
                // Start recording
                mediaRecorder.start(100); // Collect data every 100ms
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🎙️ Recording audio for validation...`);
                
            } catch (error) {
                console.error('Audio recording setup failed:', error);
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ⚠️ Audio recording unavailable: ${error.message}`);
            }
        }
        
        // Stop microphone analysis
        function stopMicrophoneAnalysis() {
            isAnalyzing = false;
            
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
            }
            
            // Stop audio recording
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            
            if (microphoneSource) {
                microphoneSource.disconnect();
            }
            
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
            }
            
            document.getElementById('startMicBtn').disabled = false;
            document.getElementById('stopMicBtn').disabled = true;
            
            // Show verify button if notes were detected
            if (detectedNotes.length > 0) {
                const verifyBtn = document.getElementById('verifyBtn');
                verifyBtn.style.display = 'inline-block';
                verifyBtn.disabled = false;
                
                // Add success message
                const timestamp = new Date().toLocaleTimeString();
                updateAnalysisDisplay(`[${timestamp}] Analysis stopped. ${detectedNotes.length} notes captured. Recording analysis will be available shortly...`);
            }
        }
        
        // Clear analysis display
        function clearAnalysis() {
            document.getElementById('liveAnalysis').innerHTML = '';
            detectedNotes = [];
            document.getElementById('verifyBtn').style.display = 'none';
            document.getElementById('verifyBtn').disabled = true;
            
            // Hide validation interface
            document.getElementById('validationSection').style.display = 'none';
            
            // Clean up recorded audio
            if (recordedAudioUrl) {
                URL.revokeObjectURL(recordedAudioUrl);
                recordedAudioUrl = null;
            }
            recordedAudioBlob = null;
            recordedChunks = [];
        }
        
        // Show validation interface after recording
        function showValidationInterface() {
            const validationSection = document.getElementById('validationSection');
            validationSection.style.display = 'block';
            
            // Enable playback buttons
            document.getElementById('playOriginalBtn').disabled = false;
            document.getElementById('playEngineBtn').disabled = false;
            document.getElementById('playBothBtn').disabled = false;
            document.getElementById('analyzeBtn').disabled = false;
            document.getElementById('downloadBtn').disabled = false;
            
            updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔬 Validation interface ready! You can now compare your voice with engine detection.`);
        }
        
        // Verify what you sang - play back detected notes
        async function verifyWhatYouSang() {
            if (detectedNotes.length === 0) {
                updateAnalysisDisplay('[ERROR] No notes to verify!');
                return;
            }
            
            try {
                const verifyBtn = document.getElementById('verifyBtn');
                verifyBtn.disabled = true;
                verifyBtn.textContent = '🔊 Playing Back...';
                
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🎵 Playing back ${detectedNotes.length} detected notes...`);
                
                // Group notes by time intervals to avoid too rapid playback
                const groupedNotes = groupNotesByInterval(detectedNotes, 500); // 500ms intervals
                
                for (let i = 0; i < groupedNotes.length; i++) {
                    const noteGroup = groupedNotes[i];
                    const avgFreq = noteGroup.reduce((sum, note) => sum + note.frequency, 0) / noteGroup.length;
                    const analysis = getDetailedSvaraAnalysis(avgFreq);
                    
                    // Play the note
                    await playTone(avgFreq, 0.8, `${analysis.closestSvara} (${avgFreq.toFixed(1)} Hz)`);
                    
                    // Short pause between notes
                    if (i < groupedNotes.length - 1) {
                        await delay(200);
                    }
                }
                
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ✅ Playback complete! You sang ${groupedNotes.length} distinct notes.`);
                
            } catch (error) {
                console.error('Verification playback error:', error);
                updateAnalysisDisplay(`[ERROR] Playback failed: ${error.message}`);
            } finally {
                const verifyBtn = document.getElementById('verifyBtn');
                verifyBtn.disabled = false;
                verifyBtn.textContent = '🔍 Verify What You Sang';
            }
        }
        
        // Group notes by time intervals to create cleaner playback
        function groupNotesByInterval(notes, intervalMs) {
            if (notes.length === 0) return [];
            
            const grouped = [];
            let currentGroup = [notes[0]];
            
            for (let i = 1; i < notes.length; i++) {
                const timeDiff = notes[i].relativeTime - notes[i-1].relativeTime;
                
                if (timeDiff < intervalMs) {
                    currentGroup.push(notes[i]);
                } else {
                    grouped.push(currentGroup);
                    currentGroup = [notes[i]];
                }
            }
            
            // Add the last group
            if (currentGroup.length > 0) {
                grouped.push(currentGroup);
            }
            
            return grouped;
        }
        
        // Play a single tone with WebAudio API (reusing from Sa-Pa-Sa demo)
        function playTone(frequency, duration, noteName = '') {
            return new Promise((resolve) => {
                if (!audioContext) {
                    resolve();
                    return;
                }
                
                // Create oscillator for sine wave tone
                const oscillator = audioContext.createOscillator();
                const gainNode = audioContext.createGain();
                
                // Connect oscillator -> gain -> output
                oscillator.connect(gainNode);
                gainNode.connect(audioContext.destination);
                
                // Configure the tone
                oscillator.frequency.setValueAtTime(frequency, audioContext.currentTime);
                oscillator.type = 'sine'; // Pure sine wave for clear pitch
                
                // Smooth volume envelope (fade in/out to avoid clicks)
                const now = audioContext.currentTime;
                gainNode.gain.setValueAtTime(0, now);
                gainNode.gain.linearRampToValueAtTime(0.2, now + 0.1); // Fade in
                gainNode.gain.linearRampToValueAtTime(0.2, now + duration - 0.1); // Hold
                gainNode.gain.linearRampToValueAtTime(0, now + duration); // Fade out
                
                // Start and stop the tone
                oscillator.start(now);
                oscillator.stop(now + duration);
                
                // Show live feedback
                if (noteName) {
                    updateAnalysisDisplay(`🔊 Playing: ${noteName}`);
                }
                
                // Resolve when tone ends
                oscillator.onended = resolve;
            });
        }
        
        // Simple delay utility (reusing from Sa-Pa-Sa demo)
        function delay(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }
        
        // Start Sa-Pa-Sa shruti detection
        async function startShrutiDetection() {
            try {
                isDetectingShruti = true;
                saPaPatternBuffer = [];
                detectedSaFrequency = null;
                detectedPaFrequency = null;
                saPaCycles = 0;
                
                document.getElementById('detectShrutiBtn').disabled = true;
                document.getElementById('liveAnalysis').innerHTML = `
                    <div class="info">🎵 Listening for Sa-Pa-Sa-Pa pattern...<br>
                    Please sing: Sa → Pa → Sa → Pa → Sa → Pa → Sa<br>
                    Hold each note steady for 1-2 seconds.</div>
                `;
                
                // Start microphone if not already running
                if (!isAnalyzing) {
                    await startMicrophoneAnalysis();
                }
                
                // Listen for Sa-Pa pattern for 15 seconds
                setTimeout(() => {
                    if (isDetectingShruti) {
                        analyzeSaPaPattern();
                    }
                }, 15000);
            } catch (error) {
                console.error('Shruti detection error:', error);
                document.getElementById('liveAnalysis').innerHTML = `
                    <div class="error">❌ Shruti detection error: ${error.message}</div>
                `;
                document.getElementById('detectShrutiBtn').disabled = false;
            }
        }
        
        // Analyze Sa-Pa pattern
        function analyzeSaPaPattern() {
            isDetectingShruti = false;
            document.getElementById('detectShrutiBtn').disabled = false;
            
            if (detectedSaFrequency && saPaCycles >= 2) {
                // Convert frequency to note name
                const noteResult = musicSystem.frequencyToNote(detectedSaFrequency);
                
                document.getElementById('liveAnalysis').innerHTML = `
                    <div class="success">✅ Shruti detected: ${noteResult.note}<br>
                    Completed ${saPaCycles} Sa-Pa-Sa cycles<br>
                    Setting as reference...</div>
                `;
                
                // Update shruti selection
                const shrutiSelect = document.getElementById('shrutiSelect');
                for (let option of shrutiSelect.options) {
                    if (Math.abs(parseFloat(option.value) - detectedSaFrequency) < 10) {
                        shrutiSelect.value = option.value;
                        break;
                    }
                }
            } else {
                document.getElementById('liveAnalysis').innerHTML = `
                    <div class="error">❌ Could not detect clear Sa-Pa pattern<br>
                    Please try again with steady notes.</div>
                `;
            }
        }
        
        // Play test note
        function playTestNote() {
            initAudio();
            
            if (testOscillator) {
                testOscillator.stop();
            }
            
            const frequency = parseFloat(document.getElementById('testNote').value);
            
            testOscillator = audioContext.createOscillator();
            testOscillator.frequency.value = frequency;
            testOscillator.type = 'sine';
            
            const gainNode = audioContext.createGain();
            gainNode.gain.value = 0.3;
            
            testOscillator.connect(gainNode);
            gainNode.connect(audioContext.destination);
            
            testOscillator.start();
        }
        
        // Stop test note
        function stopTestNote() {
            if (testOscillator) {
                testOscillator.stop();
                testOscillator = null;
            }
        }
        
        // Analyze test note
        function analyzeTestNote() {
            const frequency = parseFloat(document.getElementById('testNote').value);
            
            if (musicSystem) {
                const result = musicSystem.analyzeFrequency(frequency);
                
                let output = '<div class="success">';
                const systemType = document.getElementById('musicSystem').value;
                
                switch (systemType) {
                    case 'western':
                        output += `Note: ${result.note}<br>`;
                        output += `Octave: ${result.octave}<br>`;
                        output += `Frequency: ${frequency} Hz<br>`;
                        output += `Cents deviation: ${result.cents}`;
                        break;
                    case 'carnatic':
                    case 'hindustani':
                        output += `Swara: ${result.swara}<br>`;
                        output += `Octave: ${result.octave}<br>`;
                        output += `Frequency: ${frequency} Hz<br>`;
                        if (result.possibleRagas) {
                            output += `Possible Ragas: ${result.possibleRagas.join(', ')}`;
                        }
                        break;
                }
                output += '</div>';
                
                document.getElementById('testNoteAnalysis').innerHTML = output;
            }
        }
        
        // 🔊 Sa-Pa-Sa Demo Audio Synthesis
        async function playSaPaDemo() {
            const demoBtn = document.getElementById('demoBtn');
            
            try {
                demoBtn.disabled = true;
                demoBtn.textContent = '🔊 Playing Demo...';
                
                updateAnalysisDisplay('<div class="info">🎵 Playing Sa-Pa-Sa demonstration...<br><br>Listen carefully to learn the correct pitch pattern:<br>• Sa = base note (Madhya Sthayi)<br>• Pa = perfect fifth higher (1.5x frequency)<br>• Sa₊₁ = higher octave (Tara Sthayi)<br>• Pa₋₁ = lower octave Pa (Mandra Sthayi)<br>• Pattern: Sa → Pa → Sa₊₁ → Pa → Sa → Pa₋₁ → Sa</div>');
                
                // Initialize audio context if not already done
                if (!audioContext) {
                    await initAudio();
                }
                
                // Get user-selected Shruti (Sa frequency)
                const shrutiSelect = document.getElementById('shrutiSelect');
                let saFreq = 261.63; // Default to C4
                
                if (shrutiSelect.value !== 'auto') {
                    saFreq = parseFloat(shrutiSelect.value);
                }
                
                updateAnalysisDisplay(`Using selected Shruti: ${saFreq.toFixed(1)} Hz for Sa-Pa-Sa demo`);
                const paFreq = saFreq * 1.5; // Perfect fifth: G4 (392.44 Hz)
                const saHighFreq = saFreq * 2; // Tara Sthayi Sa (C5 - 523.26 Hz)
                const paLowFreq = paFreq / 2; // Mandra Sthayi Pa (G3 - 196.22 Hz)
                
                // Play complete Sa-Pa-Sa+1-Pa-Sa-Pa-1-Sa pattern
                await playTone(saFreq, 1.0, 'Sa'); // Sa (Madhya)
                await delay(150);
                await playTone(paFreq, 1.0, 'Pa'); // Pa (Madhya)
                await delay(150);
                await playTone(saHighFreq, 1.0, 'Sa₊₁'); // Sa (Tara)
                await delay(150);
                await playTone(paFreq, 1.0, 'Pa'); // Pa (Madhya)
                await delay(150);  
                await playTone(saFreq, 1.0, 'Sa'); // Sa (Madhya)
                await delay(150);
                await playTone(paLowFreq, 1.0, 'Pa₋₁'); // Pa (Mandra)
                await delay(150);
                await playTone(saFreq, 1.2, 'Sa'); // Final Sa (Madhya)
                
                updateAnalysisDisplay(`<div class="success">✅ Complete Sa-Pa-Sa octave pattern demo complete!<br><br>Now you try:<br>1. Tap "🎵 Detect Shruti"<br>2. Sing the same pattern: Sa → Pa → Sa₊₁ → Pa → Sa → Pa₋₁ → Sa<br>3. Include all three octaves (Mandra, Madhya, Tara)<br><br>Frequencies used (based on your selected Shruti):<br>• Sa (Madhya): ${saFreq.toFixed(1)} Hz<br>• Pa (Madhya): ${paFreq.toFixed(1)} Hz<br>• Sa₊₁ (Tara): ${saHighFreq.toFixed(1)} Hz<br>• Pa₋₁ (Mandra): ${paLowFreq.toFixed(1)} Hz<br>• Perfect fifth ratio: ${(paFreq/saFreq).toFixed(3)}</div>`);
                
            } catch (error) {
                updateAnalysisDisplay(`<div class="error">❌ Demo playback failed: ${error.message}</div>`);
            } finally {
                demoBtn.disabled = false;
                demoBtn.textContent = '🔊 Play Sa-Pa-Sa Demo';
            }
        }
        
        // Play a single tone with WebAudio API
        function playTone(frequency, duration, noteName) {
            return new Promise((resolve) => {
                if (!audioContext) {
                    resolve();
                    return;
                }
                
                // Create oscillator for sine wave tone
                const oscillator = audioContext.createOscillator();
                const gainNode = audioContext.createGain();
                
                // Connect oscillator -> gain -> output
                oscillator.connect(gainNode);
                gainNode.connect(audioContext.destination);
                
                // Configure the tone
                oscillator.frequency.setValueAtTime(frequency, audioContext.currentTime);
                oscillator.type = 'sine'; // Pure sine wave for clear pitch
                
                // Smooth volume envelope (fade in/out to avoid clicks)
                const now = audioContext.currentTime;
                gainNode.gain.setValueAtTime(0, now);
                gainNode.gain.linearRampToValueAtTime(0.3, now + 0.1); // Fade in
                gainNode.gain.linearRampToValueAtTime(0.3, now + duration - 0.1); // Hold
                gainNode.gain.linearRampToValueAtTime(0, now + duration); // Fade out
                
                // Start and stop the tone
                oscillator.start(now);
                oscillator.stop(now + duration);
                
                // Show live feedback
                updateAnalysisDisplay(`<div class="info">🎵 Playing ${noteName}: ${frequency.toFixed(1)} Hz</div>`);
                
                // Resolve when tone ends
                oscillator.onended = resolve;
            });
        }
        
        // Simple delay utility
        function delay(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }
        
        // Play original recorded audio
        function playOriginalRecording() {
            if (!recordedAudioUrl) {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ No recording available`);
                return;
            }
            
            const audio = new Audio(recordedAudioUrl);
            audio.play().then(() => {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🎤 Playing your original voice...`);
            }).catch(error => {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ Playback failed: ${error.message}`);
            });
        }
        
        // Play engine detection (reuse existing verifyWhatYouSang)
        function playEngineDetection() {
            updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔍 Playing engine detection...`);
            verifyWhatYouSang();
        }
        
        // Play both together for comparison
        async function playBothTogether() {
            if (!recordedAudioUrl || detectedNotes.length === 0) {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ Need both recording and detected notes`);
                return;
            }
            
            updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ⚖️ Playing both recordings together for comparison...`);
            
            // Start original recording
            const audio = new Audio(recordedAudioUrl);
            audio.volume = 0.7; // Reduce volume slightly
            
            // Start engine playback simultaneously
            const playBoth = async () => {
                // Start original audio
                audio.play();
                
                // Start engine synthesis with small delay for synchronization
                setTimeout(() => {
                    verifyWhatYouSang();
                }, 100);
            };
            
            await playBoth();
        }
        
        // Download recorded audio
        function downloadRecording() {
            if (!recordedAudioBlob) {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ No recording to download`);
                return;
            }
            
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5);
            const filename = `voice-recording-${timestamp}.webm`;
            
            const a = document.createElement('a');
            a.href = recordedAudioUrl;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            
            updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 💾 Downloaded: ${filename}`);
        }
        
        // Run confidence analysis
        async function runConfidenceAnalysis() {
            if (!recordedAudioBlob || detectedNotes.length === 0) {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ Need both recording and detected notes for analysis`);
                return;
            }
            
            try {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔬 Analyzing confidence... This may take a moment.`);
                
                const analysisBtn = document.getElementById('analyzeBtn');
                analysisBtn.disabled = true;
                analysisBtn.textContent = '🔬 Analyzing...';
                
                // Extract fundamental frequency from original recording
                const originalF0Data = await extractF0FromRecording(recordedAudioBlob);
                
                // Calculate confidence metrics
                const confidenceScore = calculateConfidenceScore(originalF0Data, detectedNotes);
                
                // Display results
                displayConfidenceResults(confidenceScore);
                
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ✅ Confidence analysis complete: ${confidenceScore.overall.toFixed(1)}%`);
                
            } catch (error) {
                console.error('Confidence analysis error:', error);
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ Analysis failed: ${error.message}`);
            } finally {
                const analysisBtn = document.getElementById('analyzeBtn');
                analysisBtn.disabled = false;
                analysisBtn.textContent = '🎖️ Analyze Confidence';
            }
        }
        
        // Extract fundamental frequency from recorded audio
        async function extractF0FromRecording(audioBlob) {
            return new Promise((resolve, reject) => {
                const audio = new Audio(URL.createObjectURL(audioBlob));
                audio.addEventListener('loadeddata', async () => {
                    try {
                        // Create audio context for analysis
                        const analysisContext = new (window.AudioContext || window.webkitAudioContext)();
                        
                        // Convert blob to audio buffer
                        const arrayBuffer = await audioBlob.arrayBuffer();
                        const audioBuffer = await analysisContext.decodeAudioData(arrayBuffer);
                        
                        // Extract F0 using autocorrelation method
                        const f0Data = extractF0UsingAutocorrelation(audioBuffer, analysisContext.sampleRate);
                        
                        resolve(f0Data);
                    } catch (error) {
                        reject(error);
                    }
                });
                audio.load();
            });
        }
        
        // Extract F0 using autocorrelation method
        function extractF0UsingAutocorrelation(audioBuffer, sampleRate) {
            const channelData = audioBuffer.getChannelData(0);
            const frameSize = 2048;
            const hopSize = 512;
            const f0Data = [];
            
            for (let i = 0; i < channelData.length - frameSize; i += hopSize) {
                const frame = channelData.slice(i, i + frameSize);
                const f0 = estimateF0Autocorrelation(frame, sampleRate);
                
                if (f0 > 50 && f0 < 2000) { // Valid frequency range
                    f0Data.push({
                        time: i / sampleRate,
                        frequency: f0,
                        amplitude: calculateRMS(frame)
                    });
                }
            }
            
            return f0Data;
        }
        
        // Estimate F0 using autocorrelation
        function estimateF0Autocorrelation(signal, sampleRate) {
            const minPeriod = Math.floor(sampleRate / 800); // Max 800 Hz
            const maxPeriod = Math.floor(sampleRate / 80);  // Min 80 Hz
            
            let maxCorrelation = 0;
            let bestPeriod = 0;
            
            // Autocorrelation
            for (let period = minPeriod; period < maxPeriod && period < signal.length / 2; period++) {
                let correlation = 0;
                let count = 0;
                
                for (let i = 0; i < signal.length - period; i++) {
                    correlation += signal[i] * signal[i + period];
                    count++;
                }
                
                correlation /= count;
                
                if (correlation > maxCorrelation) {
                    maxCorrelation = correlation;
                    bestPeriod = period;
                }
            }
            
            return bestPeriod > 0 ? sampleRate / bestPeriod : 0;
        }
        
        // Calculate RMS amplitude
        function calculateRMS(signal) {
            let sum = 0;
            for (let i = 0; i < signal.length; i++) {
                sum += signal[i] * signal[i];
            }
            return Math.sqrt(sum / signal.length);
        }
        
        // Calculate comprehensive confidence score
        function calculateConfidenceScore(originalF0Data, detectedNotes) {
            // Convert detected notes to time-frequency pairs
            const engineData = detectedNotes.map(note => ({
                time: note.relativeTime / 1000, // Convert to seconds
                frequency: note.frequency,
                amplitude: 1.0 // Detected notes don't have amplitude info
            }));
            
            // Calculate individual metrics
            const pitchAccuracy = calculatePitchAccuracy(originalF0Data, engineData);
            const timingAccuracy = calculateTimingAccuracy(originalF0Data, engineData);
            const completenessScore = calculateCompleteness(originalF0Data, engineData);
            const amplitudeCorrelation = calculateAmplitudeCorrelation(originalF0Data, engineData);
            
            // Calculate overall score with weights
            const overall = (
                pitchAccuracy.score * 0.40 +
                timingAccuracy.score * 0.25 +
                completenessScore.score * 0.20 +
                amplitudeCorrelation.score * 0.15
            );
            
            return {
                overall,
                pitchAccuracy,
                timingAccuracy,
                completenessScore,
                amplitudeCorrelation,
                originalDataPoints: originalF0Data.length,
                engineDataPoints: engineData.length
            };
        }
        
        // Calculate pitch accuracy
        function calculatePitchAccuracy(originalData, engineData) {
            if (originalData.length === 0 || engineData.length === 0) {
                return { score: 0, details: 'No data to compare' };
            }
            
            let totalError = 0;
            let comparisonCount = 0;
            
            for (const enginePoint of engineData) {
                // Find closest original data point in time
                const closest = originalData.reduce((prev, curr) => 
                    Math.abs(curr.time - enginePoint.time) < Math.abs(prev.time - enginePoint.time) ? curr : prev
                );
                
                if (Math.abs(closest.time - enginePoint.time) < 0.5) { // Within 500ms
                    const cents = 1200 * Math.log2(enginePoint.frequency / closest.frequency);
                    totalError += Math.abs(cents);
                    comparisonCount++;
                }
            }
            
            if (comparisonCount === 0) {
                return { score: 0, details: 'No matching time points' };
            }
            
            const avgError = totalError / comparisonCount;
            const score = Math.max(0, 100 - avgError); // 100% if perfect, decreases with error
            
            return {
                score: Math.min(100, score),
                details: `Avg error: ${avgError.toFixed(1)} cents`,
                avgError,
                comparisonCount
            };
        }
        
        // Calculate timing accuracy
        function calculateTimingAccuracy(originalData, engineData) {
            // Simple metric: how well do note onsets align
            let totalTimingError = 0;
            let matchedOnsets = 0;
            
            for (const enginePoint of engineData) {
                const closest = originalData.reduce((prev, curr) => 
                    Math.abs(curr.time - enginePoint.time) < Math.abs(prev.time - enginePoint.time) ? curr : prev
                );
                
                const timeDiff = Math.abs(closest.time - enginePoint.time) * 1000; // Convert to ms
                if (timeDiff < 1000) { // Within 1 second
                    totalTimingError += timeDiff;
                    matchedOnsets++;
                }
            }
            
            if (matchedOnsets === 0) {
                return { score: 0, details: 'No matching onsets' };
            }
            
            const avgTimingError = totalTimingError / matchedOnsets;
            const score = Math.max(0, 100 - avgTimingError / 10); // 100% if 0ms, decreases by 10% per 100ms
            
            return {
                score: Math.min(100, score),
                details: `Avg drift: ${avgTimingError.toFixed(0)}ms`,
                avgTimingError,
                matchedOnsets
            };
        }
        
        // Calculate completeness (missed notes vs false positives)
        function calculateCompleteness(originalData, engineData) {
            const tolerance = 0.3; // 300ms tolerance
            
            let matchedOriginal = 0;
            let falsePositives = 0;
            
            // Count how many original points have nearby engine detections
            for (const originalPoint of originalData) {
                const hasMatch = engineData.some(enginePoint => 
                    Math.abs(enginePoint.time - originalPoint.time) < tolerance
                );
                if (hasMatch) matchedOriginal++;
            }
            
            // Count false positives (engine detections without nearby originals)
            for (const enginePoint of engineData) {
                const hasMatch = originalData.some(originalPoint => 
                    Math.abs(originalPoint.time - enginePoint.time) < tolerance
                );
                if (!hasMatch) falsePositives++;
            }
            
            const missedNotes = originalData.length - matchedOriginal;
            const precision = engineData.length > 0 ? (engineData.length - falsePositives) / engineData.length : 0;
            const recall = originalData.length > 0 ? matchedOriginal / originalData.length : 0;
            const f1Score = precision + recall > 0 ? 2 * (precision * recall) / (precision + recall) : 0;
            
            return {
                score: f1Score * 100,
                details: `${missedNotes} missed, ${falsePositives} false`,
                missedNotes,
                falsePositives,
                precision: precision * 100,
                recall: recall * 100
            };
        }
        
        // Calculate amplitude correlation
        function calculateAmplitudeCorrelation(originalData, engineData) {
            // Check if engine detects during high amplitude periods
            let correctDetections = 0;
            let totalEngineDetections = engineData.length;
            
            if (totalEngineDetections === 0) {
                return { score: 0, details: 'No engine detections' };
            }
            
            for (const enginePoint of engineData) {
                // Find original data around this time
                const nearbyOriginal = originalData.filter(orig => 
                    Math.abs(orig.time - enginePoint.time) < 0.5
                );
                
                if (nearbyOriginal.length > 0) {
                    const avgAmplitude = nearbyOriginal.reduce((sum, p) => sum + p.amplitude, 0) / nearbyOriginal.length;
                    if (avgAmplitude > 0.01) { // Threshold for "audible" sound
                        correctDetections++;
                    }
                }
            }
            
            const score = (correctDetections / totalEngineDetections) * 100;
            
            return {
                score,
                details: `${correctDetections}/${totalEngineDetections} during sound`,
                correctDetections,
                totalEngineDetections
            };
        }
        
        // Display confidence results
        function displayConfidenceResults(results) {
            const resultsDiv = document.getElementById('confidenceResults');
            resultsDiv.style.display = 'block';
            
            const scoreColor = results.overall >= 80 ? '#48bb78' : 
                             results.overall >= 60 ? '#ed8936' : '#f56565';
            
            const scoreStars = results.overall >= 90 ? '⭐⭐⭐⭐⭐' :
                              results.overall >= 75 ? '⭐⭐⭐⭐' :
                              results.overall >= 60 ? '⭐⭐⭐' :
                              results.overall >= 40 ? '⭐⭐' : '⭐';
            
            resultsDiv.innerHTML = `
                <div class="overall-score">
                    <h3 style="color: ${scoreColor}">Overall Confidence: ${results.overall.toFixed(1)}% ${scoreStars}</h3>
                    <div class="score-bar">
                        <div class="score-fill" style="width: ${results.overall}%"></div>
                    </div>
                </div>
                
                <div class="detailed-breakdown">
                    <div class="metric">
                        <span>🎵 Pitch Accuracy:</span>
                        <span class="score">${results.pitchAccuracy.score.toFixed(1)}%</span>
                        <span class="details">${results.pitchAccuracy.details}</span>
                    </div>
                    
                    <div class="metric">
                        <span>⏱️ Timing Accuracy:</span>
                        <span class="score">${results.timingAccuracy.score.toFixed(1)}%</span>
                        <span class="details">${results.timingAccuracy.details}</span>
                    </div>
                    
                    <div class="metric">
                        <span>🎯 Note Detection:</span>
                        <span class="score">${results.completenessScore.score.toFixed(1)}%</span>
                        <span class="details">${results.completenessScore.details}</span>
                    </div>
                    
                    <div class="metric">
                        <span>🔊 Amplitude Sync:</span>
                        <span class="score">${results.amplitudeCorrelation.score.toFixed(1)}%</span>
                        <span class="details">${results.amplitudeCorrelation.details}</span>
                    </div>
                </div>
                
                <div class="recommendations">
                    <h5>🔧 Analysis Summary:</h5>
                    <ul>
                        <li>📊 Original audio: ${results.originalDataPoints} data points</li>
                        <li>🤖 Engine detected: ${results.engineDataPoints} notes</li>
                        ${generateRecommendations(results)}
                    </ul>
                </div>
            `;
        }
        
        // Generate recommendations based on analysis
        function generateRecommendations(results) {
            const recommendations = [];
            
            if (results.pitchAccuracy.score < 70) {
                recommendations.push('<li>⚠️ Pitch accuracy could be improved - check microphone quality</li>');
            } else if (results.pitchAccuracy.score > 90) {
                recommendations.push('<li>✅ Excellent pitch accuracy!</li>');
            }
            
            if (results.timingAccuracy.score < 60) {
                recommendations.push('<li>⚠️ Timing drift detected - consider audio latency compensation</li>');
            }
            
            if (results.completenessScore.missedNotes > results.engineDataPoints * 0.2) {
                recommendations.push('<li>⚠️ Engine missed some notes - try speaking/singing louder</li>');
            }
            
            if (results.completenessScore.falsePositives > results.originalDataPoints * 0.1) {
                recommendations.push('<li>⚠️ Engine detected false notes - improve noise reduction</li>');
            }
            
            if (results.amplitudeCorrelation.score > 85) {
                recommendations.push('<li>✅ Good silence detection - noise gate working well</li>');
            }
            
            if (results.overall >= 85) {
                recommendations.push('<li>🎉 Engine performance is excellent for your voice!</li>');
            } else if (results.overall < 60) {
                recommendations.push('<li>💡 Consider adjusting microphone position and room acoustics</li>');
            }
            
            return recommendations.join('');
        }
        
        // Test engine with synthetic audio
        async function testEngine() {
            updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔧 Testing engine with synthetic 440Hz signal...`);
            
            try {
                // Create synthetic 440Hz signal
                const sampleRate = 44100;
                const duration = 2048; // samples
                const frequency = 440; // A4
                const testBuffer = new Float32Array(duration);
                
                for (let i = 0; i < duration; i++) {
                    testBuffer[i] = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 0.5;
                }
                
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔧 Generated test buffer: ${testBuffer.length} samples`);
                
                // Test engine components
                if (!audioProcessor) {
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ AudioProcessor not available`);
                    return;
                }
                
                if (!musicSystem) {
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ MusicSystem not available`);
                    return;
                }
                
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔧 Both components available, processing...`);
                
                // Process with engine
                const result = await audioProcessor.processAudio(testBuffer);
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🔧 Engine result: ${JSON.stringify(result)}`);
                
                if (result && result.fundamentalFrequency) {
                    const musicAnalysis = musicSystem.analyzeFrequency(result.fundamentalFrequency);
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ✅ SUCCESS! Detected: ${result.fundamentalFrequency.toFixed(2)}Hz (expected 440Hz)`);
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] 🎵 Music analysis: ${JSON.stringify(musicAnalysis)}`);
                } else {
                    updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ Engine failed to detect frequency in test signal`);
                }
                
            } catch (error) {
                updateAnalysisDisplay(`[${new Date().toLocaleTimeString()}] ❌ Engine test error: ${error.message}`);
                console.error('Engine test error:', error);
            }
        }
    </script>
</body>
</html>